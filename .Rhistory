plot(fitmod$residuals, pch = 19, cex =2)
plot(fitmod$residuals, pch = 19, cex =.4)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
rm(list = ls())
data(AlzheimerDisease)
rm(list = ls(
))
data("concrete")
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
plot(training$CompressiveStrength)
names(training)
str(training)
library(Hmisc)
training$Age = cut2(training$Age, g = 3)
qplot(CompressiveStrength, color = Age, data = training)
qplot(CompressiveStrength, color = Age, data = training, geom = "points")
qplot(CompressiveStrength, color = Age, data = training, geom = "point")
qplot(CompressiveStrength, y = 1:774, color = Age, data = training)
qplot(CompressiveStrength, x = 1:774, color = Age, data = training)
training$Age = cut2(training$Age, g = 4)
training = mixtures[inTrain]
training = mixtures[inTrain,]
training$Age = cut2(training$Age, g = 4)
qplot(CompressiveStrength, x = 1:774, color = Age, data = training)
qplot(CompressiveStrength, x = 1:774, color = FlyAsh, data = training)
qplot(CompressiveStrength, x = 1:774, color = Age, data = training)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
qplot(Superplasticizer, data = training)
qplot(log(Superplasticizer), data = training)
qplot(log(Superplasticizer+1), data = training)
log(-5)
qplot(log(Superplasticizer), data = training)
summary(training$Superplasticizer)
set.seed(3433)data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(3433);data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(3433);data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]];training = adData[ inTrain,]
testing = adData[-inTrain,]
grepl(^[IL], names(training))
grepl(^IL, names(training))
grepl("^[IL]", names(training))
sum(grepl("^[IL]", names(training)))
vars = (grep("^[IL]", names(training)))
training = subset(training, select = vars)
prComp = preProcess(training, method = "pca")
prComp
attributes(prComp)
prComp$ranges
prComp$pcaComp
prComp = preProcess(training, method = "pca", tresh = 0.9)
prComp
prComp = preProcess(training, method = "pca", list(thresh = 0.8))
prComp
prComp = preProcess(training, method = "pca", thresh = 0.8)
prComp
prComp = preProcess(training, method = "pca", thresh = 0.9)
prComp
names(training)
grepl("^IL", names(training))
training = subset(training, select = grep("^IL",names(training)))
prComp = preProcess(training, method = "pca", thresh = 0.9)
prComp
set.seed(3433);data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]];training = adData[ inTrain,]
testing = adData[-inTrain,]
training = subset(training, select = c(grep("^IL", names(training)), 131))
names(training)
names(testing)[1]
set.seed(3433);data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]];training = adData[ inTrain,]
testing = adData[-inTrain,]
training = subset(training, select = c(grep("^IL", names(training)), 1))
t2 = subset(training, select = 2:12)
mod1 = train(diagnosis ~., data = training, method = glm)
mod1 = train(diagnosis ~., data = training, method = "glm")
pred = predict(mod1, newdata = testing)
confusionMatrix(pred, testing$diagnosis)
t = preProcess(t2, method = "pca", thresh = 0.8)
t2 = predict(t, t2)
head(t2)
tr = data.frame(training$diagnosis, t2)
mod = train(tr$diagnosis ~., data = tr, method = "glm")
mod = train(diagnosis ~., data = tr, method = "glm")
head(tr)
mod = train(training.diagnosis ~., data = tr, method = "glm")
names(tr) = c("diagnosis","PC1","PC2","PC3","PC4","PC5","PC6")
mod = train(diagnosis ~., data = tr, method = "glm")
confusionMatrix(predict(mod, testing), testing$diagnosis)
modfit = train(diagnosis ~., method = "glm", preProcess = "pca", data = training, trControl = trainControl(prePocOptions = list(thresh = 0.8)))
modfit = train(diagnosis ~., method = "glm", preProcess = "pca", data = training, trControl = trainControl(prePocOptions = thresh = 0.8))
modfit = train(diagnosis ~., method = "glm", preProcess = "pca", data = training, trControl = trainControl(preProcOptions = list(thresh = 0.8)))
confusionMatrix(predict(modfit, testing) , testing$diagnosis)
prComp = preProcess(training, method = "pca", thresh = 0.8)
prComp
rm(list = ls())
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
library(Hmisc)
training$Age = cut2(training$Age, g = 3)
str(training$Age)
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
training$Age = cut2(training$Age, g = 4)
table(training$Age)
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
training$Age = cut2(training$Age, g = 12)
table(training$Age)
ggplot(data = training, y = CompressiveStrength, x = 1:774, col = Age) + geom_point()
qplot(data = training, y = CompressiveStrength, x = 1:774, col = Age)
rm(list = ls())
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]training = adData[ inTrain,]
testing = adData[-inTrain,]
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]];training = adData[ inTrain,]
testing = adData[-inTrain,]
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433);data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]];training = adData[ inTrain,]
testing = adData[-inTrain,]
trainingIL = training[,grep("^IL", names(training))]
prComp = preProcess(trainingIL, method = "pca", thresh = 0.8)
prComp$pcaComp
prComp$dim
prComp
prComp = preProcess(trainingIL, method = "pca", thresh = 0.9)
prComp
rm(list = ls())
library(plotly)
plot_ly(mtcars, x = wt, y = mpg , mode = "markers")
data(mtcars)
mtcars
plot_ly(mtcars, x = wt, y = mpg , mode = "markers")
plot_ly(data = mtcars, x = wt, y = mpg , mode = "markers")
with(mtcars, plot_ly(x = wt, y = mpg, mode = "markers"))
plot_ly(mtcars, x = wt, y = mpg, mode = "markers")
set.seed(2016-07-21)
temp <- rnorm(100, mean = 30, sd = 5)
pressue <- rnorm(100)
dtime <- 1:100
plot_ly(x = temp, y = pressue, z = dtime,
type = "scatter3d", mode = "markers", color = temp)
plot(pressure)
install.packages("leaflet")
library(leaflet)
my_map <- leaflet() %>%
addTiles()
my_map
my_map <- my_map %>%
addMarkers(lat=39.2980803, lng=-76.5898801,
popup="Jeff Leek's Office")
my_map
rm(list = ls())
library(ElemStatLearn); data(prostate)
str(prostate)
install.packages("quantmod")
-library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.test = transform(vowel.test, y = factor(y))
vowel.train = transform(vowel.train, y = factor(y))
str(c(vowel.test, vowel.train))
set.seed(33833)
install.packaged("gbm")
install.packages("gbm")
mod1 = train(y ~., data = vowel.train, method = "rf")
library(caret)
mod1 = train(y ~., data = vowel.train, method = "rf")
mod2 = train(y ~., data = vowel.train, method = "gbm")
rm(mod1)
set.seed(33833)
mod1 = train(y ~., data = vowel.train, method = "rf")
mod2 = train(y ~., data = vowel.train, method = "gbm", verbose = F)
missClass = function(values, prediction){sum(((prediction > 0.5)*1) != values)/ length(values)}
pred1 = predict(mod1, newdata = vowel.test)
missClass = function(values, prediction){sum(prediction != values)/ length(values)}
pred2 = predict(mod2, newdata = vowel.test)
missClass(vowel.test$y, pred1)
Acc = function(values, prediction){sum((prediction == values)*1)/ length(values)}
rm(missClass)
Acc(vowel.test$y, pred1)
Acc(vowel.test$y, pred2)
version(rpart)
version
Acc(pred1,pred2)
?gbm
?caret
??caret
sessionInfo()
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
modrf = train(diagnosis ~., data = training, method = "rf")
modgbm = train(diagnosis ~., data = training, method = "gbm", verbose = F)
modlda = train(diagnosis ~., data = training, method = "lda")
predrf = predict(modrf, testing)
prdgbm = predict(modgbm, tesing)
prdgbm = predict(modgbm, testing)
predlda = predict(modlada, testing)
predlda = predict(modlda, testing)
rm(list = ls()[grepl("pred", ls())])
rm(prdgbm)
predrf = predict(modrf, training)
predgbm = predict(modgbm, training)
predlda = predict(modlda, training)
pred = data.frame(predrf = predrf, predgbm = predgbm, predlda = predlda)
predrf = predict(modrf, testing)
predgmb = predict(modgbm, testing)
predlda = predict(modlda, testing)
predt = data.frame(predrf = predrf, predgbm = predgmb, predlda = predlda)
predt = cbind(diagnosis = testing$diagnosis, predt)
str(predt)
pred = cbind(diagnosis = training$diagnosis, pred)
mod = train(diagnosis ~. ,data = pred, method = "rf")
predd = predict(mod, predt)
Acc = fucntion(values, prediction){sum((predictions == values)*1) / length(values)}
Acc = fucntion(values, prediction){sum((predictions == values)*1)) / length(values)}
Acc = fucntion(values, prediction){sum((predictions == values)*1) / length(values) }
Acc = fucntion(values, prediction)sum((predictions == values)*1) / length(values)
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
rm(missClass)
Acc = function(values, prediction)sum((predictions == values)*1) / length(values)
Acc(predt$diagnosis, predd)
Acc = function(values, prediction)sum((prediction == values)*1) / length(values)
Acc(predt$diagnosis, predd)
Acc(testing$diagnosis, predrf)
Acc(testing$diagnosis, predgmb)
Acc(testing$diagnosis, predlda)
sessionInfo()
rm(list = ls())
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
library(caret)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
?plot.enet
??plot.enet
x<-model.matrix(mpg~.,data=mtcars)
str(mtcars)
table(mtcars$mpg)
rm(x, inTrain)
glmnet
install.packages("glmnet")
x = as.matrix(concrete)
head(x)
rm(x)
TR = as.matrix(training)
rm(TR)
CompressiveStrength = training$CompressiveStrength
training$CompressiveStrength = NULL
TR = as.matrix(training)
library("glmnet")
lasso = glmnet(x = TR, y = CompressiveStrength)
plot(fit, xvar = "lambda")
plot(lasso, xvar = "lambda")
plot(lasso)
attributes(lasso)
plot(lasso, xvar = "beta")
plot(lasso, xvar = "dev")
plot(lasso, xvar = "lambda")
lasso$beta
plot(lasso$lambda,lasso$beta)
plot(lasso$labmda)
rm(list = ls())
library(lubridate)
url = "https://d396qusza40orc.cloudfront.net/predmachlearn/gaData.csv"
file("https://d396qusza40orc.cloudfront.net/predmachlearn/gaData.csv", open = "rw")
con = file("https://d396qusza40orc.cloudfront.net/predmachlearn/gaData.csv", open = "rw")
con = file("https://d396qusza40orc.cloudfront.net/predmachlearn/gaData.csv", open = "rw")
con = file("https://d396qusza40orc.cloudfront.net/predmachlearn/gaData.csv", open = "rw")
con = file("https://d396qusza40orc.cloudfront.net/predmachlearn/gaData.csv", open = "rw")
dat = read.csv(con)
close(con = con)
rm(con, url)
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
year(head(dat)$date)
month(head(dat)$date)
install.packages("forecast")
library(forecast)
head(tstrain)
tail(tstrain)
mod = bats(tstrain)
str(testing)
pred(mod, testing$visitsTumblr)
pred = predict(mod, testing$visitsTumblr)
forecast(mod, level = 95)
forecast(mod, level = c(2.5, 9.5))
forecast(mod, level = c(2.5, 97.5))
plot(forecast(mod,level = c(2.5, 97.5) ))
plot(forecast(mod,level = c(2.5, 97.5) ), h = 235)
plot(forecast(mod, h = 235, level = c(2.5, 97.5) ))
x = forecast(mod, h = 235, level = c(2.5, 97.5))
plot(x)
summary(x)
x = summary(x)
class(x)
names(x)
names(x) = sub(" ",",names(x)")
sub(" ","", names(x))
names(x) = sub(" ","",names(x))
names(testing)
within = function(dfpred, df){sum((df$visitsTumblr >= dfpred$Lo2.5 && df$visitsTumblr <= Hi97.5)*1) *100/ nrow(df)}
within(x,testing)
head(testing)
x = forecast(mod, h = 235, level = 95)
x = summary(x, verbose = F)
within(x, testing)
names(x)
names(x) = sub(" ","", names(x))
within = function(dfpred, df){sum((df$visitsTumblr >= dfpred$Lo95 && df$visitsTumblr <= Hi95)*1) *100/ nrow(df)}
within(x,testing)
names(x)
within = function(dfpred, df){sum((df$visitsTumblr >= dfpred$Lo95 && df$visitsTumblr <= dfpred$Hi95)*1) *100/ nrow(df)}
within(x,testing)
lines(testing$date, testing$visitsTumblr, col = "red")
x = forecast(mod, h = 235, level = 95)
plot(x)
lines(testing$date, testing$visitsTumblr, col = "red")
x = summary(x)
within(x, testing)
names(x) = sub(" ", "", names(x))
within(x, testing)
sum(testing$visitsTumblr >= x$Lo95 && testing$visitsTumblr <= x$Hi95)
sum(testing$visitsTumblr <= x$Hi95)
sum(testing$visitsTumblr >= x$Lo95 )
sum(testing$visitsTumblr >= x$Lo95 & testing$visitsTumblr <= x$Hi95)
within = function(dfpred, df){sum((df$visitsTumblr >= dfpred$Lo95 & df$visitsTumblr <= dfpred$Hi95)*1) *100/ nrow(df)}
within(x,testing)
rm(list = ls())
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
library(e1071)
set.seed(325)
?svm
mod = svm(CompressiveStrength ~., data = training)
pred = predict(mod, testing)
RMSE(pred, testing$CompressiveStrength)
sqrt(sum((pred - testing$CompressiveStrength)^2))
sqrt(sum((pred - testing$CompressiveStrength)^2)/256)
rm(list = ls())
sessionInfo()
library(plotly)
plot_ly(mtcars, x = wt, y = mpg, mode = "markers")
data("mtcars")
library(plotly)
plot_ly(mtcars, x = wt, y = mpg, mode = "markers")
library(plotly)
plot_ly(mtcars, x = wt, y = mpg, mode = "markers")
mtcars %>% plot_ly(x= wt, y =mpg, mod = "markers")
with(mtcars, plot_ly(x = wt,  y = mpg, mode = "markers"))
with(mtcars, plot_ly(x = wt,  y = mpg, mode = "markers", type = "scatter"))
?mtcars
with(mtcars, plot_ly(x = wt,  y = mpg, mode = "markers", type = "scatter", color = "cyl"))
with(mtcars, plot_ly(x = wt,  y = mpg, mode = "markers", type = "scatter", color = cyl))
with(mtcars, plot_ly(x = wt,  y = mpg, mode = "markers", type = "scatter", color = factor(cyl)))
with(mtcars, plot_ly(x = wt,  y = mpg, mode = "markers", type = "scatter", color = factor(cyl), size = factor(hp)))
with(mtcars, plot_ly(x = wt,  y = mpg, mode = "markers", type = "scatter", color = factor(cyl), size = factor(hp)))
with(mtcars, plot_ly(x = wt,  y = mpg, mode = "markers", type = "scatter", color = factor(cyl), size = hp ))
set.seed(2016-07-21)
temp <- rnorm(100, mean = 30, sd = 5)
pressue <- rnorm(100)
dtime <- 1:100
plot_ly(x = temp, y = pressue, z = dtime,
type = "scatter3d", mode = "markers", color = temp)
data("airmiles")
str(airmiles)
head(airmiles)
airmiles
x = as.ts(temp)
rm(x)
x = cbind(year = 1901:2000, temp)
x = as.ts(x)
x
rm(x)
x = as.ts(temp, start = 1901, end = 2000)
x
x = as.ts(temp, Start = 1901, End = 2000)
x
rm(x)
plot_ly(x = time(airmiles), y = airmiles)
plot_ly(x = time(airmiles), y = airmiles, type = "timeseries")
plot_ly(x = time(airmiles), y = airmiles, type = "pie")
plot_ly(x = time(airmiles), y = airmiles, type = "choropleth")
plot_ly(x = time(airmiles), y = airmiles, type = "surface")
plot_ly(x = time(airmiles), y = airmiles, type = "contour")
plot_ly(x = time(airmiles), y = airmiles, type = "area")
data("EuStockMarkets")
library(tidyr)
library(dplyr)
stocks <- as.data.frame(EuStockMarkets) %>%
gather(index, price) %>%
mutate(time = rep(time(EuStockMarkets), 4))
head(stocks)
with(stocks, plot_ly(x = time, y = price, col = index))
with(stocks, plot_ly(x = time, y = price, color  = index))
with(stocks, plot_ly(x = time, y = price, color  = index, type = "area"))
with(iris, plot_ly(y = Petal.Length, color = Species, type = "box"))
rm(list = ls())
setwd("~/Documents/MOOC materials/Data Science Specialization/Practical Machine Learning/Project")
pml = read.csv("pml-training.csv")
str(pml)
names(pml)
head(pml$classe, 30)
rm(list = ls())
setwd("~/GIT/Exercise-Quality-Prediction-PML-")
pml = read.csv("/Users/Gbolly/Documents/MOOC materials/Data Science Specialization/Practical Machine Learning/Project/pml_training.csv")
pml = read.csv("./Users/Gbolly/Documents/MOOC materials/Data Science Specialization/Practical Machine Learning/Project/pml_training.csv")
pml = read.csv("~/Documents/MOOC materials/Data Science Specialization/Practical Machine Learning/Project/pml_training.csv")
pml = read.csv("~/Documents/MOOC materials/Data Science Specialization/Practical Machine Learning/Project/pml-training.csv")
pml = read.csv("/Users/Gbolly/Documents/MOOC materials/Data Science Specialization/Practical Machine Learning/Project/pml-training.csv")
if(exists("~/Documents/MOOC materials/Data Science Specialization/Practical Machine Learning/Project/pml-training.csv")) "yea"
if(exists("~/Documents/MOOC materials/Data Science Specialization/Practical Machine Learning/Project/pml-training.csv")) "yea"
if(exists("~/Documents/MOOC materials/Data Science Specialization/Practical Machine Learning/Project/pml-training.csv"))
"yea"
"yea"
exists("~/Documents/MOOC materials/Data Science Specialization/Practical Machine Learning/Project/pml-training.csv")
exists("/Users/Gbolly/Documents/MOOC materials/Data Science Specialization/Practical Machine Learning/Project/pml-training.csv")
file.exists("~/Documents/MOOC materials/Data Science Specialization/Practical Machine Learning/Project/pml-training.csv")
if(file.exists("~/Documents/MOOC materials/Data Science Specialization/Practical Machine Learning/Project/pml-training.csv"))
"yea"
if(!file.exists("~/Documents/MOOC materials/Data Science Specialization/Practical Machine Learning/Project/pml-training.csv")){
urlTrain = "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
download.file(destfile = "~/Documents/MOOC materials/Data Science Specialization/Practical Machine Learning/Project/pml-training.csv", url = urlTrain)
} else if(!file.exists("~/Documents/MOOC materials/Data Science Specialization/Practical Machine Learning/Project/pml-testing.csv")){
urlTest = "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
download.file(destfile = "~/Documents/MOOC materials/Data Science
Specialization/Practical Machine Learning/Project/pml-testing.csv", url = urlTest)
}
TrainFile = "~/Documents/MOOC materials/Data Science Specialization/Practical Machine Learning/Project/pml-training.csv"
TestFile = "~/Documents/MOOC materials/Data Science Specialization/Practical Machine Learning/Project/pml-testing.csv"
Training = read.csv(TrainFile)
Testing = read.csv(TestFile)
mod = lm(facor(caste) ~ ., data = Training)
mod = lm(factor(caste) ~ ., data = Training)
mod = lm(factor(classe) ~ ., data = Training)
str(Training$classe)
mod = lm(classe ~ ., data = Training)
mod = glm(classe ~., data = Training, family = "binomial")
